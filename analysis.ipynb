{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# DWH Project: Comprehensive Data Analysis\n",
    "\n",
    "This notebook performs a full analysis of the three provided CSV files to prepare for the DWH project.\n",
    "\n",
    "**Goals:**\n",
    "1.  **Cleaning:** Clean and prepare data for SQL loading.\n",
    "2.  **Integrity:** Check primary key uniqueness and referential integrity (orphaned records).\n",
    "3.  **EDA:** Understand the distributions of key dimensions for the 20 analytical queries.\n",
    "4.  **ETL Simulation:** Simulate the final \"Transformed Data\" by joining all tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 0. Imports and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set display options for better output\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully from 'Data/' directory.\n",
      "\n",
      "--- Customer Master Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5891 entries, 0 to 5890\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Unnamed: 0                  5891 non-null   int64 \n",
      " 1   Customer_ID                 5891 non-null   int64 \n",
      " 2   Gender                      5891 non-null   object\n",
      " 3   Age                         5891 non-null   object\n",
      " 4   Occupation                  5891 non-null   int64 \n",
      " 5   City_Category               5891 non-null   object\n",
      " 6   Stay_In_Current_City_Years  5891 non-null   int64 \n",
      " 7   Marital_Status              5891 non-null   int64 \n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 368.3+ KB\n",
      "\n",
      "--- Product Master Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3631 entries, 0 to 3630\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        3631 non-null   int64  \n",
      " 1   Product_ID        3631 non-null   object \n",
      " 2   Product_Category  3631 non-null   object \n",
      " 3   price$            3631 non-null   float64\n",
      " 4   storeID           3631 non-null   int64  \n",
      " 5   supplierID        3631 non-null   int64  \n",
      " 6   storeName         3631 non-null   object \n",
      " 7   supplierName      3631 non-null   object \n",
      "dtypes: float64(1), int64(3), object(4)\n",
      "memory usage: 227.1+ KB\n",
      "\n",
      "--- Transactional Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Unnamed: 0   550068 non-null  int64 \n",
      " 1   orderID      550068 non-null  int64 \n",
      " 2   Customer_ID  550068 non-null  int64 \n",
      " 3   Product_ID   550068 non-null  object\n",
      " 4   quantity     550068 non-null  int64 \n",
      " 5   date         550068 non-null  object\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cs_master = pd.read_csv('Data/customer_master_data.csv')\n",
    "    pd_master = pd.read_csv('Data/product_master_data.csv')\n",
    "    tr_data = pd.read_csv('Data/transactional_data.csv')\n",
    "    print(\"Files loaded successfully from 'Data/' directory.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Files not found in 'Data/' directory. Trying current directory...\")\n",
    "    cs_master = pd.read_csv('customer_master_data.csv')\n",
    "    pd_master = pd.read_csv('product_master_data.csv')\n",
    "    tr_data = pd.read_csv('transactional_data.csv')\n",
    "    print(\"Files loaded successfully from current directory.\")\n",
    "\n",
    "print(\"\\n--- Customer Master Info ---\")\n",
    "cs_master.info()\n",
    "print(\"\\n--- Product Master Info ---\")\n",
    "pd_master.info()\n",
    "print(\"\\n--- Transactional Data Info ---\")\n",
    "tr_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-header",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning and Preparation\n",
    "\n",
    "Prepare the DataFrames for analysis and SQL loading. This involves dropping junk columns, renaming for SQL compatibility, and setting correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clean-1-drop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 'Unnamed: 0' columns...\n",
      "Columns dropped.\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping 'Unnamed: 0' columns...\")\n",
    "\n",
    "cs_master = cs_master.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "pd_master = pd_master.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "tr_data = tr_data.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "\n",
    "print(\"Columns dropped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clean-2-rename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming 'price$' to 'price'...\n",
      "Product master columns: ['Product_ID', 'Product_Category', 'price', 'storeID', 'supplierID', 'storeName', 'supplierName']\n"
     ]
    }
   ],
   "source": [
    "print(\"Renaming 'price$' to 'price'...\")\n",
    "pd_master = pd_master.rename(columns={'price$': 'price'})\n",
    "print(f\"Product master columns: {pd_master.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clean-3-dtype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 'tr_data.date' to datetime objects...\n",
      "Data type of 'date' column: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting 'tr_data.date' to datetime objects...\")\n",
    "tr_data['date'] = pd.to_datetime(tr_data['date'])\n",
    "print(f\"Data type of 'date' column: {tr_data['date'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clean-4-pk-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Primary Key Uniqueness Check ---\n",
      "Customer_ID is unique in cs_master: True\n",
      "Product_ID is unique in pd_master:  True\n",
      "Total cs_master rows: 5891, Unique Customer_IDs: 5891\n",
      "Total pd_master rows: 3631, Unique Product_IDs:  3631\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Primary Key Uniqueness Check ---\")\n",
    "print(f\"Customer_ID is unique in cs_master: {cs_master['Customer_ID'].is_unique}\")\n",
    "print(f\"Product_ID is unique in pd_master:  {pd_master['Product_ID'].is_unique}\")\n",
    "\n",
    "print(f\"Total cs_master rows: {len(cs_master)}, Unique Customer_IDs: {cs_master['Customer_ID'].nunique()}\")\n",
    "print(f\"Total pd_master rows: {len(pd_master)}, Unique Product_IDs:  {pd_master['Product_ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrity-header",
   "metadata": {},
   "source": [
    "## 2. Referential Integrity Analysis (Orphaned Records)\n",
    "\n",
    "This is the MOST important check for the ETL process. Do all transactions in `tr_data` have a matching customer and product in the master tables? Any transaction that *doesn't* is an \"orphaned record\" and will fail the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "integrity-1-customer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking for Orphaned Customer Records ---\n",
      "GOOD: All Customer_IDs in transactions exist in the customer master table.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Checking for Orphaned Customer Records ---\")\n",
    "unique_trans_cust = set(tr_data['Customer_ID'].unique())\n",
    "unique_master_cust = set(cs_master['Customer_ID'].unique())\n",
    "\n",
    "orphaned_cust_ids = unique_trans_cust - unique_master_cust\n",
    "\n",
    "if not orphaned_cust_ids:\n",
    "    print(\"GOOD: All Customer_IDs in transactions exist in the customer master table.\")\n",
    "else:\n",
    "    print(f\"WARNING: Found {len(orphaned_cust_ids)} orphaned Customer_IDs in transactions.\")\n",
    "    print(f\"Example orphans: {list(orphaned_cust_ids)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "integrity-2-product",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking for Orphaned Product Records ---\n",
      "GOOD: All Product_IDs in transactions exist in the product master table.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Checking for Orphaned Product Records ---\")\n",
    "unique_trans_prod = set(tr_data['Product_ID'].unique())\n",
    "unique_master_prod = set(pd_master['Product_ID'].unique())\n",
    "\n",
    "orphaned_prod_ids = unique_trans_prod - unique_master_prod\n",
    "\n",
    "if not orphaned_prod_ids:\n",
    "    print(\"GOOD: All Product_IDs in transactions exist in the product master table.\")\n",
    "else:\n",
    "    print(f\"WARNING: Found {len(orphaned_prod_ids)} orphaned Product_IDs in transactions.\")\n",
    "    print(f\"Example orphans: {list(orphaned_prod_ids)[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-header",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Understand the distributions and unique values of the key dimension attributes. This is essential for writing the 20 analytical queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-cust-header",
   "metadata": {},
   "source": [
    "### 3.1 Customer Dimension (`cs_master`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda-1-customer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Customer Dimension Analysis ---\n",
      "\n",
      "Distribution of 'Age' (for Q2, Q4, Q10):\n",
      "Age\n",
      "0-17      218\n",
      "18-25    1069\n",
      "26-35    2053\n",
      "36-45    1167\n",
      "46-50     531\n",
      "51-55     481\n",
      "55+       372\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'Occupation' (for Q3, Q5):\n",
      "Occupation\n",
      "0     688\n",
      "1     517\n",
      "2     256\n",
      "3     170\n",
      "4     740\n",
      "5     111\n",
      "6     228\n",
      "7     669\n",
      "8      17\n",
      "9      88\n",
      "10    192\n",
      "11    128\n",
      "12    376\n",
      "13    140\n",
      "14    294\n",
      "15    140\n",
      "16    235\n",
      "17    491\n",
      "18     67\n",
      "19     71\n",
      "20    273\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'City_Category' (for Q2, Q6, Q8):\n",
      "City_Category\n",
      "A    1045\n",
      "B    1707\n",
      "C    3139\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'Gender' (for Q2, Q4, Q7):\n",
      "Gender\n",
      "M    4225\n",
      "F    1666\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'Marital_Status' (for Q6):\n",
      "Marital_Status\n",
      "0    3417\n",
      "1    2474\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'Stay_In_Current_City_Years' (for Q7):\n",
      "Stay_In_Current_City_Years\n",
      "0     772\n",
      "1    2086\n",
      "2    1145\n",
      "3     979\n",
      "4     909\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Customer Dimension Analysis ---\")\n",
    "print(\"\\nDistribution of 'Age' (for Q2, Q4, Q10):\")\n",
    "print(cs_master['Age'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nDistribution of 'Occupation' (for Q3, Q5):\")\n",
    "print(cs_master['Occupation'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nDistribution of 'City_Category' (for Q2, Q6, Q8):\")\n",
    "print(cs_master['City_Category'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nDistribution of 'Gender' (for Q2, Q4, Q7):\")\n",
    "print(cs_master['Gender'].value_counts())\n",
    "\n",
    "print(\"\\nDistribution of 'Marital_Status' (for Q6):\")\n",
    "print(cs_master['Marital_Status'].value_counts())\n",
    "\n",
    "print(\"\\nDistribution of 'Stay_In_Current_City_Years' (for Q7):\")\n",
    "print(cs_master['Stay_In_Current_City_Years'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-prod-header",
   "metadata": {},
   "source": [
    "### 3.2 Product Dimension (`pd_master`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda-2-product",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Product Dimension Analysis ---\n",
      "\n",
      "Distribution of 'Product_Category' (for Q3, Q5, Q8, Q9):\n",
      "Product_Category\n",
      "Toys                        1047\n",
      "Health & Beauty              967\n",
      "Grocery                      493\n",
      "Patio & Garden               254\n",
      "Electronics                  152\n",
      "Household Essentials         119\n",
      "Baby                         102\n",
      "Arts, Crafts & Sewing         98\n",
      "Home & Kitchen                90\n",
      "Clothing                      88\n",
      "Office & School Supplies      44\n",
      "Appliances                    44\n",
      "Furniture                     35\n",
      "Books, Movies & Music         30\n",
      "Pets                          25\n",
      "Automotive                    25\n",
      "Pharmacy & OTC                11\n",
      "Shoes                          3\n",
      "Sports & Outdoors              2\n",
      "Jewelry & Accessories          2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Stores, Suppliers, and Categories:\n",
      "Number of unique 'storeName':    8 (for Q12, Q13, Q15, Q17)\n",
      "Number of unique 'supplierName': 7 (for Q13, Q15, Q17)\n",
      "\n",
      "Statistical Summary of 'price' (for Q1, Q18):\n",
      "count    3631.000000\n",
      "mean       41.098144\n",
      "std        22.357224\n",
      "min         2.020000\n",
      "25%        21.785000\n",
      "50%        41.340000\n",
      "75%        60.395000\n",
      "max        79.950000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Product Dimension Analysis ---\")\n",
    "print(\"\\nDistribution of 'Product_Category' (for Q3, Q5, Q8, Q9):\")\n",
    "print(pd_master['Product_Category'].value_counts())\n",
    "\n",
    "print(\"\\nUnique Stores, Suppliers, and Categories:\")\n",
    "print(f\"Number of unique 'storeName':    {pd_master['storeName'].nunique()} (for Q12, Q13, Q15, Q17)\")\n",
    "print(f\"Number of unique 'supplierName': {pd_master['supplierName'].nunique()} (for Q13, Q15, Q17)\")\n",
    "\n",
    "print(\"\\nStatistical Summary of 'price' (for Q1, Q18):\")\n",
    "print(pd_master['price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda-fact-header",
   "metadata": {},
   "source": [
    "### 3.3 Transactions Fact (`tr_data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda-3-fact-time",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transaction Data Time Analysis ---\n",
      "Earliest transaction date: 2015-01-01 00:00:00\n",
      "Latest transaction date:   2020-12-31 00:00:00\n",
      "\n",
      "Transaction counts by year:\n",
      "date\n",
      "2015    91870\n",
      "2016    91935\n",
      "2017    91627\n",
      "2018    91258\n",
      "2019    91821\n",
      "2020    91557\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Transaction Data Time Analysis ---\")\n",
    "print(f\"Earliest transaction date: {tr_data['date'].min()}\")\n",
    "print(f\"Latest transaction date:   {tr_data['date'].max()}\")\n",
    "\n",
    "# This is critical for queries like Q12 (\"for 2017\")\n",
    "print(\"\\nTransaction counts by year:\")\n",
    "print(tr_data['date'].dt.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda-4-fact-measures",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transaction Data Measures Analysis ---\n",
      "\n",
      "Statistical Summary of 'quantity' (for Q18):\n",
      "count    550068.000000\n",
      "mean          1.998338\n",
      "std           0.816231\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           3.000000\n",
      "Name: quantity, dtype: float64\n",
      "\n",
      "Distribution of 'quantity':\n",
      "quantity\n",
      "1    183694\n",
      "2    183594\n",
      "3    182780\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Transaction Data Measures Analysis ---\")\n",
    "print(\"\\nStatistical Summary of 'quantity' (for Q18):\")\n",
    "print(tr_data['quantity'].describe())\n",
    "\n",
    "print(\"\\nDistribution of 'quantity':\")\n",
    "print(tr_data['quantity'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda-5-fact-hotkeys",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'Hot Key' Analysis (for HYBRIDJOIN efficiency) ---\n",
      "\n",
      "Top 10 most frequent Customer_IDs:\n",
      "Customer_ID\n",
      "1001680    1026\n",
      "1004277     979\n",
      "1001941     898\n",
      "1001181     862\n",
      "1000889     823\n",
      "1003618     767\n",
      "1001150     752\n",
      "1001015     740\n",
      "1005795     729\n",
      "1005831     727\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 most frequent Product_IDs:\n",
      "Product_ID\n",
      "P00265242    1880\n",
      "P00025442    1615\n",
      "P00110742    1612\n",
      "P00112142    1562\n",
      "P00057642    1470\n",
      "P00184942    1440\n",
      "P00046742    1438\n",
      "P00058042    1422\n",
      "P00145042    1406\n",
      "P00059442    1406\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 'Hot Key' Analysis (for HYBRIDJOIN efficiency) ---\")\n",
    "print(\"\\nTop 10 most frequent Customer_IDs:\")\n",
    "print(tr_data['Customer_ID'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nTop 10 most frequent Product_IDs:\")\n",
    "print(tr_data['Product_ID'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etl-header",
   "metadata": {},
   "source": [
    "## 4. Simulating the Final Joined Data (ETL Verification)\n",
    "\n",
    "This final step simulates the full ETL join process. The resulting `full_df` DataFrame is exactly what your `HYBRIDJOIN` algorithm is meant to produce and load into the DW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "etl-1-merge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating ETL Joins...\n",
      "Joins complete.\n",
      "Original transactions: 550068\n",
      "Transactions after merge: 550068\n",
      "Total records lost to orphans: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Simulating ETL Joins...\")\n",
    "\n",
    "# 1. Join transactions with customers (Stream S + Relation R1)\n",
    "# We use 'inner' join to discard any orphaned records, as is standard.\n",
    "merged_df = pd.merge(tr_data, cs_master, on='Customer_ID', how='inner')\n",
    "\n",
    "# 2. Join result with products (Result + Relation R2)\n",
    "full_df = pd.merge(merged_df, pd_master, on='Product_ID', how='inner')\n",
    "\n",
    "print(\"Joins complete.\")\n",
    "print(f\"Original transactions: {len(tr_data)}\")\n",
    "print(f\"Transactions after merge: {len(full_df)}\")\n",
    "print(f\"Total records lost to orphans: {len(tr_data) - len(full_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "etl-2-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the 'Total_Purchase' measure (quantity * price)...\n",
      "Measure created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the 'Total_Purchase' measure (quantity * price)...\")\n",
    "full_df['Total_Purchase'] = full_df['quantity'] * full_df['price']\n",
    "print(\"Measure created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "etl-3-final-view",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final 'Transformed Data' Schema ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 18 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   orderID                     550068 non-null  int64         \n",
      " 1   Customer_ID                 550068 non-null  int64         \n",
      " 2   Product_ID                  550068 non-null  object        \n",
      " 3   quantity                    550068 non-null  int64         \n",
      " 4   date                        550068 non-null  datetime64[ns]\n",
      " 5   Gender                      550068 non-null  object        \n",
      " 6   Age                         550068 non-null  object        \n",
      " 7   Occupation                  550068 non-null  int64         \n",
      " 8   City_Category               550068 non-null  object        \n",
      " 9   Stay_In_Current_City_Years  550068 non-null  int64         \n",
      " 10  Marital_Status              550068 non-null  int64         \n",
      " 11  Product_Category            550068 non-null  object        \n",
      " 12  price                       550068 non-null  float64       \n",
      " 13  storeID                     550068 non-null  int64         \n",
      " 14  supplierID                  550068 non-null  int64         \n",
      " 15  storeName                   550068 non-null  object        \n",
      " 16  supplierName                550068 non-null  object        \n",
      " 17  Total_Purchase              550068 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(8), object(7)\n",
      "memory usage: 75.5+ MB\n",
      "\n",
      "--- Final 'Transformed Data' Head ---\n",
      "   orderID  Customer_ID Product_ID  quantity       date Gender   Age  \\\n",
      "0  9914432      1000001  P00069042         1 2020-12-29      F  0-17   \n",
      "1  1676537      1000001  P00248942         3 2017-03-27      F  0-17   \n",
      "2  8910457      1000001  P00087842         1 2017-08-20      F  0-17   \n",
      "3  5044982      1000001  P00085442         1 2019-03-03      F  0-17   \n",
      "4  4176351      1000002  P00285442         1 2018-07-11      M   55+   \n",
      "\n",
      "   Occupation City_Category  Stay_In_Current_City_Years  Marital_Status  \\\n",
      "0          10             A                           2               0   \n",
      "1          10             A                           2               0   \n",
      "2          10             A                           2               0   \n",
      "3          10             A                           2               0   \n",
      "4          16             C                           4               0   \n",
      "\n",
      "  Product_Category  price  storeID  supplierID     storeName  \\\n",
      "0   Home & Kitchen  77.51        2          13    Tech Haven   \n",
      "1          Grocery   9.63        6           9   Photo World   \n",
      "2             Pets  31.66        4          18     Game Zone   \n",
      "3             Pets  23.32        1          16  Electro Mart   \n",
      "4             Toys  34.71        3          39    Sound Zone   \n",
      "\n",
      "          supplierName  Total_Purchase  \n",
      "0  Samsung Electronics           77.51  \n",
      "1           Canon Inc.           28.89  \n",
      "2           Razer Inc.           31.66  \n",
      "3     Sony Corporation           23.32  \n",
      "4           Sonos Inc.           34.71  \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Final 'Transformed Data' Schema ---\")\n",
    "full_df.info()\n",
    "\n",
    "print(\"\\n--- Final 'Transformed Data' Head ---\")\n",
    "print(full_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
